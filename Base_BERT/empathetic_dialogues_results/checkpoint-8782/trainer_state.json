{
  "best_metric": 2.0597333908081055,
  "best_model_checkpoint": "./empathetic_dialogues_results/checkpoint-8782",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 8782,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11386927806877704,
      "grad_norm": 7.315392971038818,
      "learning_rate": 1.9240871479541487e-05,
      "loss": 3.1737,
      "step": 500
    },
    {
      "epoch": 0.2277385561375541,
      "grad_norm": 7.272818565368652,
      "learning_rate": 1.8481742959082973e-05,
      "loss": 2.7866,
      "step": 1000
    },
    {
      "epoch": 0.3416078342063311,
      "grad_norm": 10.307714462280273,
      "learning_rate": 1.7722614438624462e-05,
      "loss": 2.6269,
      "step": 1500
    },
    {
      "epoch": 0.4554771122751082,
      "grad_norm": 10.752365112304688,
      "learning_rate": 1.6963485918165948e-05,
      "loss": 2.5384,
      "step": 2000
    },
    {
      "epoch": 0.5693463903438852,
      "grad_norm": 9.06167984008789,
      "learning_rate": 1.6204357397707433e-05,
      "loss": 2.5102,
      "step": 2500
    },
    {
      "epoch": 0.6832156684126622,
      "grad_norm": 9.69554615020752,
      "learning_rate": 1.544522887724892e-05,
      "loss": 2.4403,
      "step": 3000
    },
    {
      "epoch": 0.7970849464814393,
      "grad_norm": 8.148001670837402,
      "learning_rate": 1.4686100356790404e-05,
      "loss": 2.4458,
      "step": 3500
    },
    {
      "epoch": 0.9109542245502164,
      "grad_norm": 9.315814018249512,
      "learning_rate": 1.3926971836331893e-05,
      "loss": 2.3727,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.3929492691315563,
      "eval_f1": 0.3841426500290716,
      "eval_loss": 2.09999418258667,
      "eval_runtime": 58.1305,
      "eval_samples_per_second": 100.034,
      "eval_steps_per_second": 12.506,
      "step": 4391
    },
    {
      "epoch": 1.0248235026189934,
      "grad_norm": 10.902298927307129,
      "learning_rate": 1.3167843315873379e-05,
      "loss": 2.3272,
      "step": 4500
    },
    {
      "epoch": 1.1386927806877705,
      "grad_norm": 10.988476753234863,
      "learning_rate": 1.2408714795414865e-05,
      "loss": 2.1637,
      "step": 5000
    },
    {
      "epoch": 1.2525620587565474,
      "grad_norm": 12.921293258666992,
      "learning_rate": 1.164958627495635e-05,
      "loss": 2.1579,
      "step": 5500
    },
    {
      "epoch": 1.3664313368253245,
      "grad_norm": 13.501897811889648,
      "learning_rate": 1.0890457754497836e-05,
      "loss": 2.1308,
      "step": 6000
    },
    {
      "epoch": 1.4803006148941016,
      "grad_norm": 13.83825397491455,
      "learning_rate": 1.0131329234039325e-05,
      "loss": 2.1256,
      "step": 6500
    },
    {
      "epoch": 1.5941698929628787,
      "grad_norm": 13.308938026428223,
      "learning_rate": 9.37220071358081e-06,
      "loss": 2.1222,
      "step": 7000
    },
    {
      "epoch": 1.7080391710316558,
      "grad_norm": 10.394941329956055,
      "learning_rate": 8.613072193122296e-06,
      "loss": 2.1166,
      "step": 7500
    },
    {
      "epoch": 1.8219084491004327,
      "grad_norm": 13.959434509277344,
      "learning_rate": 7.853943672663784e-06,
      "loss": 2.1186,
      "step": 8000
    },
    {
      "epoch": 1.9357777271692096,
      "grad_norm": 10.65009593963623,
      "learning_rate": 7.094815152205268e-06,
      "loss": 2.1317,
      "step": 8500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.411006018916595,
      "eval_f1": 0.40448372312634967,
      "eval_loss": 2.0597333908081055,
      "eval_runtime": 58.2486,
      "eval_samples_per_second": 99.831,
      "eval_steps_per_second": 12.481,
      "step": 8782
    }
  ],
  "logging_steps": 500,
  "max_steps": 13173,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 3.697290682301645e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
