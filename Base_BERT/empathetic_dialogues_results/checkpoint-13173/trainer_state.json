{
  "best_metric": 2.0597333908081055,
  "best_model_checkpoint": "./empathetic_dialogues_results/checkpoint-8782",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 13173,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11386927806877704,
      "grad_norm": 7.315392971038818,
      "learning_rate": 1.9240871479541487e-05,
      "loss": 3.1737,
      "step": 500
    },
    {
      "epoch": 0.2277385561375541,
      "grad_norm": 7.272818565368652,
      "learning_rate": 1.8481742959082973e-05,
      "loss": 2.7866,
      "step": 1000
    },
    {
      "epoch": 0.3416078342063311,
      "grad_norm": 10.307714462280273,
      "learning_rate": 1.7722614438624462e-05,
      "loss": 2.6269,
      "step": 1500
    },
    {
      "epoch": 0.4554771122751082,
      "grad_norm": 10.752365112304688,
      "learning_rate": 1.6963485918165948e-05,
      "loss": 2.5384,
      "step": 2000
    },
    {
      "epoch": 0.5693463903438852,
      "grad_norm": 9.06167984008789,
      "learning_rate": 1.6204357397707433e-05,
      "loss": 2.5102,
      "step": 2500
    },
    {
      "epoch": 0.6832156684126622,
      "grad_norm": 9.69554615020752,
      "learning_rate": 1.544522887724892e-05,
      "loss": 2.4403,
      "step": 3000
    },
    {
      "epoch": 0.7970849464814393,
      "grad_norm": 8.148001670837402,
      "learning_rate": 1.4686100356790404e-05,
      "loss": 2.4458,
      "step": 3500
    },
    {
      "epoch": 0.9109542245502164,
      "grad_norm": 9.315814018249512,
      "learning_rate": 1.3926971836331893e-05,
      "loss": 2.3727,
      "step": 4000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.3929492691315563,
      "eval_f1": 0.3841426500290716,
      "eval_loss": 2.09999418258667,
      "eval_runtime": 58.1305,
      "eval_samples_per_second": 100.034,
      "eval_steps_per_second": 12.506,
      "step": 4391
    },
    {
      "epoch": 1.0248235026189934,
      "grad_norm": 10.902298927307129,
      "learning_rate": 1.3167843315873379e-05,
      "loss": 2.3272,
      "step": 4500
    },
    {
      "epoch": 1.1386927806877705,
      "grad_norm": 10.988476753234863,
      "learning_rate": 1.2408714795414865e-05,
      "loss": 2.1637,
      "step": 5000
    },
    {
      "epoch": 1.2525620587565474,
      "grad_norm": 12.921293258666992,
      "learning_rate": 1.164958627495635e-05,
      "loss": 2.1579,
      "step": 5500
    },
    {
      "epoch": 1.3664313368253245,
      "grad_norm": 13.501897811889648,
      "learning_rate": 1.0890457754497836e-05,
      "loss": 2.1308,
      "step": 6000
    },
    {
      "epoch": 1.4803006148941016,
      "grad_norm": 13.83825397491455,
      "learning_rate": 1.0131329234039325e-05,
      "loss": 2.1256,
      "step": 6500
    },
    {
      "epoch": 1.5941698929628787,
      "grad_norm": 13.308938026428223,
      "learning_rate": 9.37220071358081e-06,
      "loss": 2.1222,
      "step": 7000
    },
    {
      "epoch": 1.7080391710316558,
      "grad_norm": 10.394941329956055,
      "learning_rate": 8.613072193122296e-06,
      "loss": 2.1166,
      "step": 7500
    },
    {
      "epoch": 1.8219084491004327,
      "grad_norm": 13.959434509277344,
      "learning_rate": 7.853943672663784e-06,
      "loss": 2.1186,
      "step": 8000
    },
    {
      "epoch": 1.9357777271692096,
      "grad_norm": 10.65009593963623,
      "learning_rate": 7.094815152205268e-06,
      "loss": 2.1317,
      "step": 8500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.411006018916595,
      "eval_f1": 0.40448372312634967,
      "eval_loss": 2.0597333908081055,
      "eval_runtime": 58.2486,
      "eval_samples_per_second": 99.831,
      "eval_steps_per_second": 12.481,
      "step": 8782
    },
    {
      "epoch": 2.0496470052379867,
      "grad_norm": 9.358380317687988,
      "learning_rate": 6.335686631746755e-06,
      "loss": 1.9841,
      "step": 9000
    },
    {
      "epoch": 2.163516283306764,
      "grad_norm": 17.367294311523438,
      "learning_rate": 5.576558111288241e-06,
      "loss": 1.8548,
      "step": 9500
    },
    {
      "epoch": 2.277385561375541,
      "grad_norm": 17.384511947631836,
      "learning_rate": 4.817429590829728e-06,
      "loss": 1.8864,
      "step": 10000
    },
    {
      "epoch": 2.391254839444318,
      "grad_norm": 13.40444564819336,
      "learning_rate": 4.0583010703712135e-06,
      "loss": 1.8723,
      "step": 10500
    },
    {
      "epoch": 2.5051241175130947,
      "grad_norm": 14.345126152038574,
      "learning_rate": 3.2991725499127004e-06,
      "loss": 1.849,
      "step": 11000
    },
    {
      "epoch": 2.618993395581872,
      "grad_norm": 17.2197208404541,
      "learning_rate": 2.540044029454187e-06,
      "loss": 1.8751,
      "step": 11500
    },
    {
      "epoch": 2.732862673650649,
      "grad_norm": 16.777118682861328,
      "learning_rate": 1.7809155089956731e-06,
      "loss": 1.8405,
      "step": 12000
    },
    {
      "epoch": 2.846731951719426,
      "grad_norm": 15.1176176071167,
      "learning_rate": 1.0217869885371594e-06,
      "loss": 1.8507,
      "step": 12500
    },
    {
      "epoch": 2.960601229788203,
      "grad_norm": 19.364055633544922,
      "learning_rate": 2.6265846807864574e-07,
      "loss": 1.8737,
      "step": 13000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.41461736887360273,
      "eval_f1": 0.41130622440302345,
      "eval_loss": 2.091310977935791,
      "eval_runtime": 58.5049,
      "eval_samples_per_second": 99.393,
      "eval_steps_per_second": 12.426,
      "step": 13173
    }
  ],
  "logging_steps": 500,
  "max_steps": 13173,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 5.545936023452467e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
